#!/usr/bin/env python3
"""
ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ (marine_train_pmml.py ê¸°ë°˜)
- marine_train_pmml.pyì—ì„œ ê²€ì¦ëœ CMEMS ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ë“¤ ì‚¬ìš©
- ì‹¤ì œ GBIF/OBIS í•´ì–‘ìƒë¬¼ ê´€ì¸¡ ë°ì´í„° ì‚¬ìš©
- í•˜ë£¨ì¹˜ ë°ì´í„° â†’ í•™ìŠµ â†’ PMML ë‚´ë³´ë‚´ê¸°
"""

import os
import sys
import pandas as pd
import numpy as np
import xarray as xr
from datetime import datetime, timedelta
import logging
import joblib
import threading
import time
import glob
import copernicusmarine

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë™ê¸°í™”ë¥¼ ìœ„í•œ ê¸€ë¡œë²Œ ë½
download_locks = {}
lock_manager_lock = threading.Lock()

# ì£¼ìš” ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.abspath(os.path.join(BASE_DIR, "..", "data"))
CMEMS_DIR = os.path.abspath(os.path.join(BASE_DIR, "..", "..", "cmems_output"))
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CMEMS_DIR, exist_ok=True)

LOG_PATH = os.path.join(BASE_DIR, "extract_var_debug.log")

def log(message):
    """ë¡œê·¸ ë©”ì‹œì§€ ì¶œë ¥"""
    logger.info(message)
    try:
        with open(LOG_PATH, "a", encoding='utf-8') as f:
            f.write(f"{datetime.now()}: {message}\n")
    except:
        pass

# marine_train_pmml.pyì—ì„œ ê²€ì¦ëœ í•¨ìˆ˜ë“¤ ë³µì‚¬
def get_dataset_config():
    """CMEMS ë°ì´í„°ì…‹ê³¼ ë³€ìˆ˜ëª… ì„¤ì • (JSON íŒŒì¼ì—ì„œ í™•ì¸í•œ ì‹¤ì œ ë³€ìˆ˜ëª… ì‚¬ìš©)"""
    return {
        "physics": {
            "dataset_id": "cmems_mod_glo_phy_anfc_0.083deg_P1D-m",
            "variables": {
                "temperature": "tob",     # sea_water_potential_temperature_at_sea_floor
                "salinity": "sob",        # sea_water_salinity_at_sea_floor
                "sea_surface_height": "zos",      # sea_surface_height_above_geoid
                "mixed_layer_depth": "mlotst"     # ocean_mixed_layer_thickness_defined_by_sigma_theta
            }
        },
        "biogeochemistry": {
            "dataset_id": "cmems_mod_glo_bgc-bio_anfc_0.25deg_P1D-m", 
            "variables": {
                "dissolved_oxygen": "o2",         # mole_concentration_of_dissolved_molecular_oxygen_in_sea_water
                "net_primary_productivity": "nppv"  # net_primary_production_of_biomass_expressed_as_carbon_per_unit_volume_in_sea_water
            }
        }
    }

def get_file_lock(file_path):
    """íŒŒì¼ë³„ ë½ ë°˜í™˜"""
    global download_locks
    with lock_manager_lock:
        if file_path not in download_locks:
            download_locks[file_path] = threading.Lock()
        return download_locks[file_path]

def cleanup_duplicate_nc_files(date_str):
    """ì¤‘ë³µ ë‹¤ìš´ë¡œë“œëœ .nc íŒŒì¼ë“¤ ì •ë¦¬"""
    try:
        patterns = [
            f"*{date_str}*.nc",
            f"*cmems*{date_str}*.nc"
        ]
        
        for pattern in patterns:
            files = glob.glob(os.path.join(CMEMS_DIR, pattern))
            if len(files) > 2:  # phyì™€ bgc 2ê°œë³´ë‹¤ ë§ìœ¼ë©´ ì¤‘ë³µ
                files.sort(key=os.path.getmtime, reverse=True)
                # ìµœì‹  2ê°œë§Œ ë‚¨ê¸°ê³  ì‚­ì œ
                for old_file in files[2:]:
                    try:
                        os.remove(old_file)
                        log(f"[cleanup] ì¤‘ë³µ íŒŒì¼ ì‚­ì œ: {old_file}")
                    except Exception as e:
                        log(f"[cleanup] ì‚­ì œ ì‹¤íŒ¨: {old_file} - {e}")
                        
    except Exception as e:
        log(f"[cleanup] ì˜¤ë¥˜: {date_str} - {e}")

def cleanup_daily_nc_files(date_str):
    """í•˜ë£¨ì¹˜ NC íŒŒì¼ ì‚­ì œ (ë©”ëª¨ë¦¬ ì ˆì•½)"""
    try:
        patterns = [
            f"cmems_phy_{date_str}.nc",
            f"cmems_bgc_{date_str}.nc"
        ]
        
        for pattern in patterns:
            file_path = os.path.join(CMEMS_DIR, pattern)
            if os.path.exists(file_path):
                os.remove(file_path)
                log(f"[cleanup] ì¼ì¼ íŒŒì¼ ì‚­ì œ: {file_path}")
                
    except Exception as e:
        log(f"[cleanup] ì¼ì¼ ì •ë¦¬ ì‹¤íŒ¨: {date_str} - {e}")

def download_with_lock(nc_path, dataset_id, variables, start_datetime, end_datetime):
    """CMEMS ë°ì´í„° ë‹¤ìš´ë¡œë“œ - íŒŒì¼ ì ê¸ˆìœ¼ë¡œ ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ ë°©ì§€"""
    
    # íŒŒì¼ë³„ ë½ íšë“
    file_lock = get_file_lock(nc_path)
    
    with file_lock:
        # ë½ ë‚´ì—ì„œ ë‹¤ì‹œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if os.path.exists(nc_path):
            log(f"[download_with_lock] íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {nc_path}")
            return True
            
        # ì¤‘ë³µ íŒŒì¼ë“¤ì´ ìˆë‹¤ë©´ ë¨¼ì € ì •ë¦¬
        date_str = os.path.basename(nc_path).replace("cmems_phy_", "").replace("cmems_bgc_", "").replace(".nc", "")
        cleanup_duplicate_nc_files(date_str)

        try:
            log(f"[download_with_lock] ë‹¤ìš´ë¡œë“œ ì‹œì‘: {dataset_id}")
            os.makedirs(os.path.dirname(nc_path), exist_ok=True)

            # ì„ì‹œ íŒŒì¼ëª…ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ (CMEMSê°€ ìë™ìœ¼ë¡œ .ncë¥¼ ì¶”ê°€í•¨)
            temp_nc_path = nc_path + ".temp"
            
            copernicusmarine.subset(
                dataset_id=dataset_id,
                variables=variables,
                start_datetime=start_datetime,
                end_datetime=end_datetime,
                minimum_longitude=124.0,
                maximum_longitude=132.0,
                minimum_latitude=33.0,
                maximum_latitude=39.0,
                output_filename=temp_nc_path,
                overwrite=True  # ì„ì‹œ íŒŒì¼ì€ ë®ì–´ì“°ê¸° í—ˆìš©
            )

            # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ ì›ë˜ ì´ë¦„ìœ¼ë¡œ ì´ë™ (CMEMSê°€ .ncë¥¼ ì¶”ê°€í•˜ë¯€ë¡œ í™•ì¸)
            temp_files = [temp_nc_path, temp_nc_path + ".nc"]
            success_file = None
            
            for temp_file in temp_files:
                if os.path.exists(temp_file):
                    success_file = temp_file
                    break
            
            if success_file:
                os.rename(success_file, nc_path)
                log(f"[download_with_lock] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {nc_path}")
                return True
            else:
                log(f"[download_with_lock] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ì„ì‹œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                log(f"[download_with_lock] í™•ì¸í•œ ê²½ë¡œ: {temp_files}")
                return False

        except Exception as e:
            log(f"[download_with_lock] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {nc_path} - {e}")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (CMEMSê°€ .ncë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‘ ê°€ì§€ í™•ì¸)
            temp_files = [nc_path + ".temp", nc_path + ".temp.nc"]
            for temp_file in temp_files:
                try:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                        log(f"[download_with_lock] ì„ì‹œ íŒŒì¼ ì •ë¦¬: {temp_file}")
                except Exception:
                    pass
                
            return False

def download_cmems_data_for_date(data_type: str, target_date: str):
    """íŠ¹ì • ë‚ ì§œì˜ CMEMS ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    try:
        date_obj = datetime.strptime(target_date, '%Y-%m-%d')
        date_str = date_obj.strftime('%Y%m%d')
        
        start_datetime = date_obj.strftime('%Y-%m-%dT00:00:00')
        end_datetime = date_obj.strftime('%Y-%m-%dT23:59:59')
        
        datasets = get_dataset_config()
        
        if data_type == "physics":
            dataset = datasets["physics"]
            nc_path = os.path.join(CMEMS_DIR, f"cmems_phy_{date_str}.nc")
            variables = list(dataset["variables"].values())
        elif data_type == "biogeochemistry":
            dataset = datasets["biogeochemistry"]
            nc_path = os.path.join(CMEMS_DIR, f"cmems_bgc_{date_str}.nc")
            variables = list(dataset["variables"].values())
        else:
            return False
        
        return download_with_lock(
            nc_path=nc_path,
            dataset_id=dataset["dataset_id"],
            variables=variables,
            start_datetime=start_datetime,
            end_datetime=end_datetime
        )
        
    except Exception as e:
        log(f"[DOWNLOAD] {data_type} {target_date} ì‹¤íŒ¨: {e}")
        return False

def collect_cmems_data_for_date(target_date: str, grid_points):
    """íŠ¹ì • ë‚ ì§œì˜ CMEMS ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    try:
        log(f"[CMEMS] {target_date} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        date_obj = datetime.strptime(target_date, '%Y-%m-%d')
        date_str = date_obj.strftime('%Y%m%d')
        
        # 1. CMEMS ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        log(f"[CMEMS] {target_date} ë¬¼ë¦¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ...")
        phy_success = download_cmems_data_for_date("physics", target_date)
        
        log(f"[CMEMS] {target_date} ìƒí™”í•™ ë°ì´í„° ë‹¤ìš´ë¡œë“œ...")
        bgc_success = download_cmems_data_for_date("biogeochemistry", target_date)
        
        if not (phy_success and bgc_success):
            log(f"[CMEMS] {target_date} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - phy:{phy_success}, bgc:{bgc_success}")
            return pd.DataFrame()
        
        # 2. NetCDF íŒŒì¼ ë¡œë“œ
        phy_nc = os.path.join(CMEMS_DIR, f"cmems_phy_{date_str}.nc")
        bgc_nc = os.path.join(CMEMS_DIR, f"cmems_bgc_{date_str}.nc")
        
        log(f"[CMEMS] NetCDF íŒŒì¼ ë¡œë“œ: {phy_nc}, {bgc_nc}")
        
        phy_ds = xr.open_dataset(phy_nc)
        bgc_ds = xr.open_dataset(bgc_nc)
        
        log(f"[CMEMS] ë¬¼ë¦¬ ë°ì´í„° ë³€ìˆ˜: {list(phy_ds.data_vars.keys())}")
        log(f"[CMEMS] ìƒí™”í•™ ë°ì´í„° ë³€ìˆ˜: {list(bgc_ds.data_vars.keys())}")
        
        # 3. ê²©ìì ë³„ ë°ì´í„° ì¶”ì¶œ
        cmems_data = []
        for i, (lat, lon) in enumerate(grid_points):
            try:
                log(f"[CMEMS] ê²©ì {i+1}/{len(grid_points)}: ({lat}, {lon})")
                
                # ë¬¼ë¦¬ ë°ì´í„° ì¶”ì¶œ
                phy_point = phy_ds.sel(latitude=lat, longitude=lon, method='nearest')
                bgc_point = bgc_ds.sel(latitude=lat, longitude=lon, method='nearest')
                
                row_data = {
                    'lat': lat,
                    'lon': lon
                }
                
                # ë¬¼ë¦¬ ë°ì´í„° ì¶”ì¶œ (JSONì—ì„œ í™•ì¸í•œ ì‹¤ì œ ë³€ìˆ˜ëª… ì‚¬ìš©)
                try:
                    if 'tob' in phy_ds.data_vars:
                        row_data['sea_water_temperature'] = float(phy_point.tob.values[0, 0])
                    if 'sob' in phy_ds.data_vars:
                        row_data['sea_water_salinity'] = float(phy_point.sob.values[0, 0])
                    if 'zos' in phy_ds.data_vars:
                        row_data['sea_surface_height'] = float(phy_point.zos.values[0, 0])
                    if 'mlotst' in phy_ds.data_vars:
                        row_data['mixed_layer_depth'] = float(phy_point.mlotst.values[0, 0])
                except Exception as e:
                    log(f"[CMEMS] ë¬¼ë¦¬ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ ({lat}, {lon}): {e}")
                
                # ìƒí™”í•™ ë°ì´í„° ì¶”ì¶œ (JSONì—ì„œ í™•ì¸í•œ ì‹¤ì œ ë³€ìˆ˜ëª… ì‚¬ìš©)
                try:
                    if 'o2' in bgc_ds.data_vars:
                        row_data['dissolved_oxygen'] = float(bgc_point.o2.values[0, 0])
                    if 'nppv' in bgc_ds.data_vars:
                        row_data['net_primary_productivity'] = float(bgc_point.nppv.values[0, 0])
                except Exception as e:
                    log(f"[CMEMS] ìƒí™”í•™ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ ({lat}, {lon}): {e}")
                
                cmems_data.append(row_data)
                
            except Exception as e:
                log(f"[CMEMS] ê²©ì ({lat}, {lon}) ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # 4. ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        phy_ds.close()
        bgc_ds.close()
        
        if cmems_data:
            df = pd.DataFrame(cmems_data)
            log(f"[CMEMS] {target_date} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}í–‰ Ã— {len(df.columns)}ì—´")
            return df
        else:
            log(f"[CMEMS] {target_date} ë°ì´í„° ì—†ìŒ")
            return pd.DataFrame()
            
    except Exception as e:
        log(f"[CMEMS] {target_date} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()

class RealCmemsMarineTrainer:
    """ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ (marine_train_pmml ê¸°ë°˜)"""
    
    def __init__(self):
        # í•´ì–‘ìƒë¬¼ ë°ì´í„° ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from real_data_system import MarineRealDataCollector
        self.data_collector = MarineRealDataCollector()
        self.models = {}
        
        # í•œêµ­ ì—°ì•ˆ ì£¼ìš” ê²©ìì  (ì‹¤ì œ í•´ì–‘ ë°ì´í„°ê°€ ìˆëŠ” ìœ„ì¹˜)
        self.grid_points = [
            # ë™í•´
            (37.5, 129.0), (37.0, 129.5), (36.5, 130.0), (36.0, 130.5),
            (35.5, 129.5), (35.0, 129.0), (34.5, 129.5), (34.0, 130.0),
            
            # ë‚¨í•´
            (34.0, 128.5), (34.5, 128.0), (35.0, 127.5), (35.5, 127.0),
            (34.0, 127.0), (34.5, 126.5), (35.0, 126.0), (35.5, 125.5),
            
            # ì„œí•´
            (37.0, 126.0), (36.5, 126.5), (36.0, 127.0), (35.5, 126.0),
            (35.0, 125.5), (34.5, 125.0), (34.0, 124.5), (33.5, 125.0),
        ]
        
        log(f"ì‹¤ì œ CMEMS+ìƒë¬¼ ë°ì´í„° í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ê²©ìì : {len(self.grid_points)}ê°œ")

    def collect_integrated_data(self, target_date: str):
        """íŠ¹ì • ë‚ ì§œì˜ í•´ì–‘ìƒë¬¼ + CMEMS í™˜ê²½ ë°ì´í„° í†µí•© ìˆ˜ì§‘ (marine_train_pmml ê¸°ë°˜)"""
        log(f"[INTEGRATE] {target_date} í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        try:
            # 1. í•´ì–‘ìƒë¬¼ ê´€ì¸¡ ë°ì´í„° ìˆ˜ì§‘
            log("[BIO] í•´ì–‘ìƒë¬¼ ê´€ì¸¡ ë°ì´í„° ìˆ˜ì§‘...")
            biological_df = self.data_collector.collect_daily_training_data(target_date, self.grid_points)
            
            if biological_df.empty:
                log("[BIO] ìƒë¬¼ ë°ì´í„° ì—†ìŒ")
                return pd.DataFrame()
            
            log(f"[BIO] ìƒë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(biological_df)}í–‰, {len(biological_df.columns)}ì—´")
            
            # 2. CMEMS í•´ì–‘í™˜ê²½ ë°ì´í„° ìˆ˜ì§‘ (marine_train_pmml ê¸°ë°˜)
            log("[CMEMS] ì‹¤ì œ CMEMS API ë°ì´í„° ìˆ˜ì§‘...")
            cmems_df = collect_cmems_data_for_date(target_date, self.grid_points)
            
            if cmems_df.empty:
                log("[CMEMS] í™˜ê²½ ë°ì´í„° ì—†ìŒ - ìƒë¬¼ ë°ì´í„°ë§Œ ì‚¬ìš©")
                return biological_df
            
            log(f"[CMEMS] í™˜ê²½ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(cmems_df)}í–‰, {len(cmems_df.columns)}ì—´")
            
            # 3. ë°ì´í„° í†µí•©
            log("[MERGE] ìƒë¬¼ + í™˜ê²½ ë°ì´í„° í†µí•©...")
            integrated_df = self._merge_data(biological_df, cmems_df)
            
            log(f"[INTEGRATE] í†µí•© ì™„ë£Œ: {len(integrated_df)}í–‰, {len(integrated_df.columns)}ì—´")
            return integrated_df
            
        except Exception as e:
            log(f"[INTEGRATE] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()

    def _merge_data(self, biological_df, cmems_df):
        """ìƒë¬¼ ë°ì´í„°ì™€ í™˜ê²½ ë°ì´í„° í†µí•©"""
        try:
            # ìœ„ë„, ê²½ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í†µí•©
            merged_df = biological_df.merge(
                cmems_df, 
                on=['lat', 'lon'], 
                how='left', 
                suffixes=('_bio', '_env')
            )
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            numeric_cols = merged_df.select_dtypes(include=[np.number]).columns
            merged_df[numeric_cols] = merged_df[numeric_cols].fillna(0)
            
            log(f"ë°ì´í„° í†µí•©: ìƒë¬¼ {len(biological_df)}í–‰ + í™˜ê²½ {len(cmems_df)}í–‰ â†’ {len(merged_df)}í–‰")
            return merged_df
            
        except Exception as e:
            log(f"ë°ì´í„° í†µí•© ì‹¤íŒ¨: {e}")
            return biological_df

    def train_models(self, integrated_df):
        """í†µí•© ë°ì´í„°ë¡œ AI ëª¨ë¸ í›ˆë ¨"""
        log("[TRAIN] AI ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        try:
            if integrated_df.empty:
                log("í›ˆë ¨ ë°ì´í„° ì—†ìŒ")
                return False
            
            # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
            numeric_cols = integrated_df.select_dtypes(include=[np.number]).columns.tolist()
            targets = ['species_diversity_index', 'biomass_estimate', 'bloom_probability']
            features = [col for col in numeric_cols if col not in targets + ['lat', 'lon']]
            
            if len(features) < 5:
                log(f"íŠ¹ì„± ìˆ˜ ë¶€ì¡±: {len(features)}ê°œ (ìµœì†Œ 5ê°œ í•„ìš”)")
                return False
            
            log(f"ì‚¬ìš© íŠ¹ì„±: {len(features)}ê°œ")
            log(f"íŠ¹ì„± ì˜ˆì‹œ: {features[:10]}")
            
            X = integrated_df[features].fillna(0)
            
            # ê° íƒ€ê²Ÿë³„ ëª¨ë¸ í›ˆë ¨
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.model_selection import cross_val_score
            
            trained_models = {}
            
            for target in targets:
                if target in integrated_df.columns:
                    y = integrated_df[target].fillna(0)
                    
                    # Random Forest ëª¨ë¸
                    model = RandomForestRegressor(
                        n_estimators=100,
                        max_depth=15,
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        n_jobs=-1
                    )
                    
                    # ëª¨ë¸ í›ˆë ¨
                    model.fit(X, y)
                    
                    # ì„±ëŠ¥ í‰ê°€
                    train_score = model.score(X, y)
                    cv_scores = cross_val_score(model, X, y, cv=3, scoring='r2')
                    
                    trained_models[target] = {
                        'model': model,
                        'features': features,
                        'train_score': train_score,
                        'cv_score': cv_scores.mean(),
                        'cv_std': cv_scores.std()
                    }
                    
                    log(f"{target}: RÂ² = {train_score:.3f}, CV = {cv_scores.mean():.3f}Â±{cv_scores.std():.3f}")
            
            self.models = trained_models
            log(f"[TRAIN] ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ: {len(trained_models)}ê°œ")
            return True
            
        except Exception as e:
            log(f"[TRAIN] ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

    def save_models(self):
        """í›ˆë ¨ëœ ëª¨ë¸ì„ joblibì™€ PMMLë¡œ ì €ì¥"""
        log("[SAVE] ëª¨ë¸ ì €ì¥ ì‹œì‘...")
        
        try:
            if not self.models:
                log("ì €ì¥í•  ëª¨ë¸ ì—†ìŒ")
                return False
            
            saved_files = []
            
            # 1. joblib í˜•ì‹ìœ¼ë¡œ ì €ì¥
            for target, model_info in self.models.items():
                model = model_info['model']
                
                # joblib ì €ì¥
                joblib_path = f"real_cmems_marine_model_{target}.joblib"
                joblib.dump(model, joblib_path)
                saved_files.append(joblib_path)
                log(f"joblib ì €ì¥: {joblib_path}")
            
            # 2. PMML í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì‹œë„
            try:
                from sklearn2pmml import sklearn2pmml, PMMLPipeline
                from sklearn.preprocessing import StandardScaler
                
                for target, model_info in self.models.items():
                    model = model_info['model']
                    features = model_info['features']
                    
                    # PMML íŒŒì´í”„ë¼ì¸ ìƒì„±
                    pipeline = PMMLPipeline([
                        ("scaler", StandardScaler()),
                        ("regressor", model)
                    ])
                    
                    # ë”ë¯¸ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ ë§ì¶¤ (PMML ìƒì„±ìš©)
                    dummy_X = np.random.random((10, len(features)))
                    dummy_y = np.random.random(10)
                    pipeline.fit(dummy_X, dummy_y)
                    
                    # PMML ì €ì¥
                    pmml_path = f"real_cmems_marine_model_{target}.pmml"
                    sklearn2pmml(pipeline, pmml_path, with_repr=True)
                    saved_files.append(pmml_path)
                    log(f"PMML ì €ì¥: {pmml_path}")
                    
            except ImportError:
                log("sklearn2pmml íŒ¨í‚¤ì§€ ì—†ìŒ - PMML ì €ì¥ ê±´ë„ˆëœ€")
            except Exception as e:
                log(f"PMML ì €ì¥ ì‹¤íŒ¨: {e}")
            
            log(f"[SAVE] ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {len(saved_files)}ê°œ íŒŒì¼")
            return True
            
        except Exception as e:
            log(f"[SAVE] ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def run_full_pipeline(self, target_date: str):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ë°ì´í„° ìˆ˜ì§‘ â†’ í›ˆë ¨ â†’ ì €ì¥"""
        log(f"ì‹¤ì œ CMEMS+ìƒë¬¼ ë°ì´í„° ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {target_date}")
        
        try:
            # 1. í†µí•© ë°ì´í„° ìˆ˜ì§‘
            integrated_df = self.collect_integrated_data(target_date)
            
            if integrated_df.empty:
                log("í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                return False
            
            # 2. ë°ì´í„° ì €ì¥
            data_file = f"real_cmems_integrated_marine_data_{target_date.replace('-', '')}.csv"
            integrated_df.to_csv(data_file, index=False, encoding='utf-8')
            log(f"í†µí•© ë°ì´í„° ì €ì¥: {data_file}")
            
            # 3. ëª¨ë¸ í›ˆë ¨
            training_success = self.train_models(integrated_df)
            
            if not training_success:
                log("ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
                return False
            
            # 4. ëª¨ë¸ ì €ì¥
            save_success = self.save_models()
            
            if not save_success:
                log("ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨")
                return False
            
            # 5. NC íŒŒì¼ ì •ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
            date_str = target_date.replace('-', '')
            cleanup_daily_nc_files(date_str)
            
            # 6. ê²°ê³¼ ìš”ì•½
            log("="*60)
            log("ğŸ“Š ì‹¤ì œ CMEMS+ìƒë¬¼ ë°ì´í„° í•™ìŠµ ì™„ë£Œ!")
            log(f"ğŸ“… ë‚ ì§œ: {target_date}")
            log(f"ğŸ“ ê²©ìì : {len(self.grid_points)}ê°œ")
            log(f"ğŸ“Š ìµœì¢… ë°ì´í„°: {len(integrated_df)}í–‰ Ã— {len(integrated_df.columns)}ì—´")
            log(f"ğŸ¤– í›ˆë ¨ëœ ëª¨ë¸: {len(self.models)}ê°œ")
            log(f"ğŸ’¾ ì €ì¥ íŒŒì¼: {data_file}")
            
            for target, model_info in self.models.items():
                log(f"   â€¢ {target}: RÂ²={model_info['train_score']:.3f}")
            
            log("="*60)
            return True
            
        except Exception as e:
            log(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸŒŠ ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° í†µí•© AI í•™ìŠµ (marine_train_pmml ê¸°ë°˜)")
    print("="*70)
    
    # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ ì‚¬ìš© (CMEMSëŠ” ë³´í†µ 3-4ì¼ ì§€ì—°)
    target_date = "2024-09-13"  # ê³¼ê±° í™•ì‹¤í•œ ë‚ ì§œ
    print(f"ğŸ“… í•™ìŠµ ëŒ€ìƒ ë‚ ì§œ: {target_date}")
    
    try:
        # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
        trainer = RealCmemsMarineTrainer()
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        success = trainer.run_full_pipeline(target_date)
        
        if success:
            print("\nğŸ‰ ì„±ê³µ! ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° AI ëª¨ë¸ ì™„ì„±!")
            print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
            print("   â€¢ real_cmems_marine_model_*.joblib (ëª¨ë¸)")
            print("   â€¢ real_cmems_marine_model_*.pmml (PMML)")
            print("   â€¢ real_cmems_integrated_marine_data_*.csv (ë°ì´í„°)")
        else:
            print("\nâŒ ì‹¤íŒ¨! ë¬¸ì œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nğŸ’¥ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
