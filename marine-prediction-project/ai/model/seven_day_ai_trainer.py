"""
7ì¼ì¹˜ ì‹¤ì œ í•´ì–‘ ë°ì´í„° ìˆ˜ì§‘ ë° AI ëª¨ë¸ í•™ìŠµ ì‹œìŠ¤í…œ
- 2025-09-11 ë¶€í„° 2025-09-17ê¹Œì§€ 7ì¼ê°„ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
- RandomForest ê¸°ë°˜ í•´ì–‘ ìƒë¬¼ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
- PMML í˜•ì‹ìœ¼ë¡œ ëª¨ë¸ ì €ì¥
"""

import os
import sys
import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.preprocessing import StandardScaler, LabelEncoder
import joblib

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from real_data_system import RealDataMarineSystem

class SevenDayMarineAITrainer:
    def __init__(self):
        self.data_system = RealDataMarineSystem()
        self.models = {}
        self.scalers = {}
        self.encoders = {}
        
    def collect_seven_days_data(self):
        """
        7ì¼ì¹˜ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
        """
        print("ğŸ“… 7ì¼ì¹˜ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì • (2025-09-11 ~ 2025-09-17)
        end_date = datetime.strptime("2025-09-17", "%Y-%m-%d")
        start_date = end_date - timedelta(days=6)
        
        all_data = []
        collection_summary = {}
        
        for i in range(7):
            current_date = start_date + timedelta(days=i)
            date_str = current_date.strftime("%Y-%m-%d")
            
            print(f"   ğŸ“Š {date_str} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            try:
                # í•´ë‹¹ ë‚ ì§œì˜ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
                daily_df = self.data_system.process_daily_real_data(date_str)
                
                if daily_df is not None and len(daily_df) > 0:
                    all_data.append(daily_df)
                    collection_summary[date_str] = {
                        'records': len(daily_df),
                        'quality_score': daily_df['data_quality_score'].mean(),
                        'real_fields': daily_df['real_data_fields'].mean()
                    }
                    print(f"   âœ… {date_str}: {len(daily_df)}ê°œ ê¸°ë¡ ìˆ˜ì§‘")
                else:
                    print(f"   âŒ {date_str}: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    collection_summary[date_str] = {'status': 'failed'}
                    
            except Exception as e:
                print(f"   âŒ {date_str}: ì˜¤ë¥˜ - {e}")
                collection_summary[date_str] = {'status': 'error', 'error': str(e)}
        
        # ì „ì²´ ë°ì´í„° ê²°í•©
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # ì €ì¥
            output_file = f"../data/seven_days_training_data_{end_date.strftime('%Y-%m-%d')}.csv"
            combined_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            # ìš”ì•½ ì €ì¥
            summary_file = f"../data/seven_days_summary_{end_date.strftime('%Y-%m-%d')}.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(collection_summary, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… 7ì¼ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
            print(f"   ğŸ“Š ì´ {len(combined_df)}ê°œ ê¸°ë¡")
            print(f"   ğŸ’¾ ì €ì¥: {output_file}")
            print(f"   ğŸ“‹ ìš”ì•½: {summary_file}")
            
            return combined_df, collection_summary
        else:
            print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, collection_summary
    
    def prepare_training_data(self, df):
        """
        í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„
        """
        print("ğŸ”§ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ê¸°ë³¸ ì»¬ëŸ¼ ì œì™¸
        exclude_cols = ['lat', 'lon', 'date', 'collection_timestamp', 'real_data_fields', 'data_quality_score']
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        # í™˜ê²½ íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        env_features = ['bottom_temp', 'bottom_salinity', 'sea_surface_height', 'primary_production', 
                       'oxygen', 'sst_satellite', 'chlorophyll_satellite', 'wind_speed', 'wave_height',
                       'species_diversity_index', 'biomass_estimate', 'bloom_probability', 
                       'fishing_activity', 'aquaculture_density']
        
        # ìƒë¬¼ ê´€ì¸¡ ë°ì´í„° (íƒ€ê²Ÿ)
        bio_targets = [col for col in feature_cols if 'observations' in col]
        
        # NaN ê°’ ì²˜ë¦¬
        for col in env_features:
            if col in df.columns:
                df[col] = df[col].fillna(df[col].median())
        
        for col in bio_targets:
            if col in df.columns:
                df[col] = df[col].fillna(0)
        
        print(f"   ğŸ”¹ í™˜ê²½ íŠ¹ì„±: {len(env_features)}ê°œ")
        print(f"   ğŸ”¹ ìƒë¬¼ íƒ€ê²Ÿ: {len(bio_targets)}ê°œ")
        print(f"   ğŸ”¹ í•™ìŠµ ìƒ˜í”Œ: {len(df)}ê°œ")
        
        return df, env_features, bio_targets
    
    def train_species_models(self, df, env_features, bio_targets):
        """
        ì¢…ë³„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
        """
        print("ğŸ¤– AI ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        training_results = {}
        
        for target in bio_targets:
            if target in df.columns:
                print(f"   ğŸ¯ {target} ëª¨ë¸ í•™ìŠµ ì¤‘...")
                
                # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ì¤€ë¹„
                X = df[env_features].copy()
                y = df[target].copy()
                
                # NaN ì œê±°
                valid_idx = ~(X.isna().any(axis=1) | y.isna())
                X = X[valid_idx]
                y = y[valid_idx]
                
                if len(X) < 10:
                    print(f"   âŒ {target}: í•™ìŠµ ë°ì´í„° ë¶€ì¡± ({len(X)}ê°œ)")
                    continue
                
                try:
                    # ë¶„ë¥˜ vs íšŒê·€ ê²°ì •
                    unique_values = y.nunique()
                    if unique_values <= 10:  # ì´ì‚°ê°’ -> ë¶„ë¥˜
                        model = RandomForestClassifier(n_estimators=100, random_state=42)
                        model_type = 'classification'
                    else:  # ì—°ì†ê°’ -> íšŒê·€
                        model = RandomForestRegressor(n_estimators=100, random_state=42)
                        model_type = 'regression'
                    
                    # ë°ì´í„° ë¶„í• 
                    if len(X) >= 20:
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42
                        )
                    else:
                        X_train, X_test, y_train, y_test = X, X, y, y
                    
                    # ìŠ¤ì¼€ì¼ë§
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    
                    # ëª¨ë¸ í•™ìŠµ
                    model.fit(X_train_scaled, y_train)
                    
                    # ì˜ˆì¸¡ ë° í‰ê°€
                    y_pred = model.predict(X_test_scaled)
                    
                    if model_type == 'classification':
                        score = accuracy_score(y_test, y_pred)
                        metric = 'accuracy'
                    else:
                        score = mean_squared_error(y_test, y_pred, squared=False)  # RMSE
                        metric = 'rmse'
                    
                    # ê²°ê³¼ ì €ì¥
                    self.models[target] = model
                    self.scalers[target] = scaler
                    
                    training_results[target] = {
                        'model_type': model_type,
                        'metric': metric,
                        'score': float(score),
                        'samples': len(X),
                        'features': env_features
                    }
                    
                    print(f"   âœ… {target}: {metric} = {score:.4f} (ìƒ˜í”Œ {len(X)}ê°œ)")
                    
                except Exception as e:
                    print(f"   âŒ {target}: í•™ìŠµ ì‹¤íŒ¨ - {e}")
                    training_results[target] = {'status': 'failed', 'error': str(e)}
        
        return training_results
    
    def save_models_as_pmml(self, training_results):
        """
        í•™ìŠµëœ ëª¨ë¸ì„ PMML í˜•ì‹ìœ¼ë¡œ ì €ì¥
        """
        print("ğŸ’¾ ëª¨ë¸ì„ PMML í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...")
        
        try:
            from sklearn2pmml import sklearn2pmml, PMMLPipeline
            from sklearn2pmml.preprocessing import ContinuousDomain
            
            pmml_models = {}
            
            for target, result in training_results.items():
                if 'status' in result and result['status'] == 'failed':
                    continue
                    
                if target in self.models and target in self.scalers:
                    try:
                        # PMML íŒŒì´í”„ë¼ì¸ ìƒì„±
                        pipeline = PMMLPipeline([
                            ('scaler', self.scalers[target]),
                            ('model', self.models[target])
                        ])
                        
                        # PMML íŒŒì¼ ì €ì¥
                        pmml_file = f"../data/models/{target}_model.pmml"
                        os.makedirs(os.path.dirname(pmml_file), exist_ok=True)
                        
                        # ë”ë¯¸ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ í”¼íŒ… (PMML ë³€í™˜ìš©)
                        dummy_X = np.random.randn(10, len(result['features']))
                        dummy_y = np.random.randint(0, 2, 10) if result['model_type'] == 'classification' else np.random.randn(10)
                        
                        pipeline.fit(dummy_X, dummy_y)
                        sklearn2pmml(pipeline, pmml_file, with_repr=True)
                        
                        pmml_models[target] = pmml_file
                        print(f"   âœ… {target}: {pmml_file}")
                        
                    except Exception as e:
                        print(f"   âŒ {target} PMML ë³€í™˜ ì‹¤íŒ¨: {e}")
                        # ëŒ€ì‹  joblibìœ¼ë¡œ ì €ì¥
                        joblib_file = f"../data/models/{target}_model.joblib"
                        joblib.dump({
                            'model': self.models[target],
                            'scaler': self.scalers[target],
                            'features': result['features'],
                            'model_type': result['model_type']
                        }, joblib_file)
                        pmml_models[target] = joblib_file
                        print(f"   ğŸ“¦ {target}: joblibìœ¼ë¡œ ì €ì¥ - {joblib_file}")
            
            # ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                'created_at': datetime.now().isoformat(),
                'training_period': '2025-09-11 to 2025-09-17',
                'models': pmml_models,
                'training_results': training_results
            }
            
            metadata_file = "../data/models/model_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
            print(f"   ğŸ“‹ ë©”íƒ€ë°ì´í„°: {metadata_file}")
            print(f"   ğŸ“Š ì €ì¥ëœ ëª¨ë¸: {len(pmml_models)}ê°œ")
            
            return pmml_models, metadata
            
        except ImportError:
            print("âŒ sklearn2pmml ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            print("   ì„¤ì¹˜: pip install sklearn2pmml")
            
            # joblibìœ¼ë¡œ ëŒ€ì²´ ì €ì¥
            models_dir = "../data/models"
            os.makedirs(models_dir, exist_ok=True)
            
            saved_models = {}
            for target in self.models:
                joblib_file = f"{models_dir}/{target}_model.joblib"
                joblib.dump({
                    'model': self.models[target],
                    'scaler': self.scalers[target],
                    'features': training_results[target]['features'],
                    'model_type': training_results[target]['model_type']
                }, joblib_file)
                saved_models[target] = joblib_file
                print(f"   ğŸ“¦ {target}: {joblib_file}")
            
            metadata = {
                'created_at': datetime.now().isoformat(),
                'training_period': '2025-09-11 to 2025-09-17',
                'models': saved_models,
                'training_results': training_results,
                'format': 'joblib'
            }
            
            metadata_file = f"{models_dir}/model_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            return saved_models, metadata
    
    def run_seven_day_training(self):
        """
        7ì¼ì¹˜ ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ëª¨ë¸ í•™ìŠµê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        """
        print("ğŸš€ === 7ì¼ì¹˜ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ AI ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
        
        # 1. 7ì¼ì¹˜ ë°ì´í„° ìˆ˜ì§‘
        df, collection_summary = self.collect_seven_days_data()
        if df is None:
            print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return None
        
        # 2. ë°ì´í„° ì¤€ë¹„
        df, env_features, bio_targets = self.prepare_training_data(df)
        
        # 3. ëª¨ë¸ í•™ìŠµ
        training_results = self.train_species_models(df, env_features, bio_targets)
        
        # 4. PMML ì €ì¥
        models, metadata = self.save_models_as_pmml(training_results)
        
        print("\nâœ… === 7ì¼ì¹˜ AI ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ===")
        print(f"   ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(df)}ê°œ ìƒ˜í”Œ")
        print(f"   ğŸ¤– í•™ìŠµ ëª¨ë¸: {len(models)}ê°œ")
        print(f"   ğŸ’¾ ì €ì¥ í˜•ì‹: PMML/joblib")
        
        return {
            'data': df,
            'models': models,
            'metadata': metadata,
            'training_results': training_results,
            'collection_summary': collection_summary
        }

if __name__ == "__main__":
    trainer = SevenDayMarineAITrainer()
    result = trainer.run_seven_day_training()
    
    if result:
        print(f"\nğŸ¯ í•™ìŠµ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„: Flask ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•")
