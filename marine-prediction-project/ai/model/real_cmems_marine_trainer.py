#!/usr/bin/env python3
"""
ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ
- ì‹¤ì œ CMEMS API ì‚¬ìš©
- ì‹¤ì œ GBIF/OBIS í•´ì–‘ìƒë¬¼ ê´€ì¸¡ ë°ì´í„° ì‚¬ìš©
- í•˜ë£¨ì¹˜ ë°ì´í„° â†’ í•™ìŠµ â†’ PMML ë‚´ë³´ë‚´ê¸°
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
import joblib

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from real_data_system import MarineRealDataCollector
from marine_train_pmml import collect_cmems_data_for_date

class RealDataMarineTrainer:
    """ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.data_collector = MarineRealDataCollector()
        self.models = {}
        
        # í•œêµ­ ì—°ì•ˆ ì£¼ìš” ê²©ìì  (ì‹¤ì œ í•´ì–‘ ë°ì´í„°ê°€ ìˆëŠ” ìœ„ì¹˜)
        self.grid_points = [
            # ë™í•´
            (37.5, 129.0), (37.0, 129.5), (36.5, 130.0), (36.0, 130.5),
            (35.5, 129.5), (35.0, 129.0), (34.5, 129.5), (34.0, 130.0),
            
            # ë‚¨í•´
            (34.0, 128.5), (34.5, 128.0), (35.0, 127.5), (35.5, 127.0),
            (34.0, 127.0), (34.5, 126.5), (35.0, 126.0), (35.5, 125.5),
            
            # ì„œí•´
            (37.0, 126.0), (36.5, 126.5), (36.0, 127.0), (35.5, 126.0),
            (35.0, 125.5), (34.5, 125.0), (34.0, 124.5), (33.5, 125.0),
        ]
        
        logger.info(f"ì‹¤ì œ ë°ì´í„° í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ê²©ìì : {len(self.grid_points)}ê°œ")

    def collect_integrated_data(self, target_date: str):
        """íŠ¹ì • ë‚ ì§œì˜ í•´ì–‘ìƒë¬¼ + CMEMS í™˜ê²½ ë°ì´í„° í†µí•© ìˆ˜ì§‘"""
        logger.info(f"[INTEGRATE] {target_date} í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        try:
            # 1. í•´ì–‘ìƒë¬¼ ê´€ì¸¡ ë°ì´í„° ìˆ˜ì§‘
            logger.info("[BIO] í•´ì–‘ìƒë¬¼ ê´€ì¸¡ ë°ì´í„° ìˆ˜ì§‘...")
            biological_df = self.data_collector.collect_daily_training_data(target_date, self.grid_points)
            
            if biological_df.empty:
                logger.warning("[BIO] ìƒë¬¼ ë°ì´í„° ì—†ìŒ")
                return pd.DataFrame()
            
            logger.info(f"[BIO] ìƒë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(biological_df)}í–‰, {len(biological_df.columns)}ì—´")
            
            # 2. CMEMS í•´ì–‘í™˜ê²½ ë°ì´í„° ìˆ˜ì§‘
            logger.info("[CMEMS] ì‹¤ì œ CMEMS API ë°ì´í„° ìˆ˜ì§‘...")
            cmems_df = collect_cmems_data_for_date(target_date, self.grid_points)
            
            if cmems_df.empty:
                logger.warning("[CMEMS] í™˜ê²½ ë°ì´í„° ì—†ìŒ - ìƒë¬¼ ë°ì´í„°ë§Œ ì‚¬ìš©")
                return biological_df
            
            logger.info(f"[CMEMS] í™˜ê²½ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(cmems_df)}í–‰, {len(cmems_df.columns)}ì—´")
            
            # 3. ë°ì´í„° í†µí•©
            logger.info("[MERGE] ìƒë¬¼ + í™˜ê²½ ë°ì´í„° í†µí•©...")
            integrated_df = self._merge_data(biological_df, cmems_df)
            
            logger.info(f"[INTEGRATE] í†µí•© ì™„ë£Œ: {len(integrated_df)}í–‰, {len(integrated_df.columns)}ì—´")
            return integrated_df
            
        except Exception as e:
            logger.error(f"[INTEGRATE] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def _merge_data(self, biological_df, cmems_df):
        """ìƒë¬¼ ë°ì´í„°ì™€ í™˜ê²½ ë°ì´í„° í†µí•©"""
        try:
            # ìœ„ë„, ê²½ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í†µí•©
            merged_df = biological_df.merge(
                cmems_df, 
                on=['lat', 'lon'], 
                how='left', 
                suffixes=('_bio', '_env')
            )
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            numeric_cols = merged_df.select_dtypes(include=[np.number]).columns
            merged_df[numeric_cols] = merged_df[numeric_cols].fillna(0)
            
            logger.info(f"ë°ì´í„° í†µí•©: ìƒë¬¼ {len(biological_df)}í–‰ + í™˜ê²½ {len(cmems_df)}í–‰ â†’ {len(merged_df)}í–‰")
            return merged_df
            
        except Exception as e:
            logger.error(f"ë°ì´í„° í†µí•© ì‹¤íŒ¨: {e}")
            return biological_df

    def train_models(self, integrated_df):
        """í†µí•© ë°ì´í„°ë¡œ AI ëª¨ë¸ í›ˆë ¨"""
        logger.info("[TRAIN] AI ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        try:
            if integrated_df.empty:
                logger.error("í›ˆë ¨ ë°ì´í„° ì—†ìŒ")
                return False
            
            # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
            numeric_cols = integrated_df.select_dtypes(include=[np.number]).columns.tolist()
            targets = ['species_diversity_index', 'biomass_estimate', 'bloom_probability']
            features = [col for col in numeric_cols if col not in targets + ['lat', 'lon']]
            
            if len(features) < 5:
                logger.error(f"íŠ¹ì„± ìˆ˜ ë¶€ì¡±: {len(features)}ê°œ (ìµœì†Œ 5ê°œ í•„ìš”)")
                return False
            
            logger.info(f"ì‚¬ìš© íŠ¹ì„±: {len(features)}ê°œ")
            logger.info(f"íŠ¹ì„± ì˜ˆì‹œ: {features[:10]}")
            
            X = integrated_df[features].fillna(0)
            
            # ê° íƒ€ê²Ÿë³„ ëª¨ë¸ í›ˆë ¨
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.model_selection import cross_val_score
            
            trained_models = {}
            
            for target in targets:
                if target in integrated_df.columns:
                    y = integrated_df[target].fillna(0)
                    
                    # Random Forest ëª¨ë¸
                    model = RandomForestRegressor(
                        n_estimators=100,
                        max_depth=15,
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        n_jobs=-1
                    )
                    
                    # ëª¨ë¸ í›ˆë ¨
                    model.fit(X, y)
                    
                    # ì„±ëŠ¥ í‰ê°€
                    train_score = model.score(X, y)
                    cv_scores = cross_val_score(model, X, y, cv=3, scoring='r2')
                    
                    trained_models[target] = {
                        'model': model,
                        'features': features,
                        'train_score': train_score,
                        'cv_score': cv_scores.mean(),
                        'cv_std': cv_scores.std()
                    }
                    
                    logger.info(f"{target}: RÂ² = {train_score:.3f}, CV = {cv_scores.mean():.3f}Â±{cv_scores.std():.3f}")
            
            self.models = trained_models
            logger.info(f"[TRAIN] ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ: {len(trained_models)}ê°œ")
            return True
            
        except Exception as e:
            logger.error(f"[TRAIN] ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return False

    def save_models(self):
        """í›ˆë ¨ëœ ëª¨ë¸ì„ joblibì™€ PMMLë¡œ ì €ì¥"""
        logger.info("[SAVE] ëª¨ë¸ ì €ì¥ ì‹œì‘...")
        
        try:
            if not self.models:
                logger.error("ì €ì¥í•  ëª¨ë¸ ì—†ìŒ")
                return False
            
            saved_files = []
            
            # 1. joblib í˜•ì‹ìœ¼ë¡œ ì €ì¥
            for target, model_info in self.models.items():
                model = model_info['model']
                
                # joblib ì €ì¥
                joblib_path = f"real_marine_model_{target}.joblib"
                joblib.dump(model, joblib_path)
                saved_files.append(joblib_path)
                logger.info(f"joblib ì €ì¥: {joblib_path}")
            
            # 2. PMML í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì‹œë„
            try:
                from sklearn2pmml import sklearn2pmml, PMMLPipeline
                from sklearn.preprocessing import StandardScaler
                
                for target, model_info in self.models.items():
                    model = model_info['model']
                    features = model_info['features']
                    
                    # PMML íŒŒì´í”„ë¼ì¸ ìƒì„±
                    pipeline = PMMLPipeline([
                        ("scaler", StandardScaler()),
                        ("regressor", model)
                    ])
                    
                    # ë”ë¯¸ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ ë§ì¶¤ (PMML ìƒì„±ìš©)
                    dummy_X = np.random.random((10, len(features)))
                    dummy_y = np.random.random(10)
                    pipeline.fit(dummy_X, dummy_y)
                    
                    # PMML ì €ì¥
                    pmml_path = f"real_marine_model_{target}.pmml"
                    sklearn2pmml(pipeline, pmml_path, with_repr=True)
                    saved_files.append(pmml_path)
                    logger.info(f"PMML ì €ì¥: {pmml_path}")
                    
            except ImportError:
                logger.warning("sklearn2pmml íŒ¨í‚¤ì§€ ì—†ìŒ - PMML ì €ì¥ ê±´ë„ˆëœ€")
            except Exception as e:
                logger.warning(f"PMML ì €ì¥ ì‹¤íŒ¨: {e}")
            
            logger.info(f"[SAVE] ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {len(saved_files)}ê°œ íŒŒì¼")
            return True
            
        except Exception as e:
            logger.error(f"[SAVE] ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def run_full_pipeline(self, target_date: str):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ë°ì´í„° ìˆ˜ì§‘ â†’ í›ˆë ¨ â†’ ì €ì¥"""
        logger.info(f"ì‹¤ì œ ë°ì´í„° ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {target_date}")
        
        try:
            # 1. í†µí•© ë°ì´í„° ìˆ˜ì§‘
            integrated_df = self.collect_integrated_data(target_date)
            
            if integrated_df.empty:
                logger.error("í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                return False
            
            # 2. ë°ì´í„° ì €ì¥
            data_file = f"real_integrated_marine_data_{target_date.replace('-', '')}.csv"
            integrated_df.to_csv(data_file, index=False, encoding='utf-8')
            logger.info(f"í†µí•© ë°ì´í„° ì €ì¥: {data_file}")
            
            # 3. ëª¨ë¸ í›ˆë ¨
            training_success = self.train_models(integrated_df)
            
            if not training_success:
                logger.error("ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
                return False
            
            # 4. ëª¨ë¸ ì €ì¥
            save_success = self.save_models()
            
            if not save_success:
                logger.error("ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨")
                return False
            
            # 5. ê²°ê³¼ ìš”ì•½
            logger.info("="*60)
            logger.info("ğŸ“Š ì‹¤ì œ ë°ì´í„° í•™ìŠµ ì™„ë£Œ!")
            logger.info(f"ğŸ“… ë‚ ì§œ: {target_date}")
            logger.info(f"ğŸ“ ê²©ìì : {len(self.grid_points)}ê°œ")
            logger.info(f"ğŸ“Š ìµœì¢… ë°ì´í„°: {len(integrated_df)}í–‰ Ã— {len(integrated_df.columns)}ì—´")
            logger.info(f"ğŸ¤– í›ˆë ¨ëœ ëª¨ë¸: {len(self.models)}ê°œ")
            logger.info(f"ğŸ’¾ ì €ì¥ íŒŒì¼: {data_file}")
            
            for target, model_info in self.models.items():
                logger.info(f"   â€¢ {target}: RÂ²={model_info['train_score']:.3f}")
            
            logger.info("="*60)
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸŒŠ ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° í†µí•© AI í•™ìŠµ")
    print("="*60)
    
    # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ ì‚¬ìš© (CMEMSëŠ” ë³´í†µ 3-4ì¼ ì§€ì—°)
    target_date = "2025-09-14"  # 3ì¼ ì „ ë°ì´í„°
    print(f"ğŸ“… í•™ìŠµ ëŒ€ìƒ ë‚ ì§œ: {target_date}")
    
    try:
        # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
        trainer = RealDataMarineTrainer()
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        success = trainer.run_full_pipeline(target_date)
        
        if success:
            print("\nğŸ‰ ì„±ê³µ! ì‹¤ì œ CMEMS + í•´ì–‘ìƒë¬¼ ë°ì´í„° AI ëª¨ë¸ ì™„ì„±!")
            print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
            print("   â€¢ real_marine_model_*.joblib (ëª¨ë¸)")
            print("   â€¢ real_marine_model_*.pmml (PMML)")
            print("   â€¢ real_integrated_marine_data_*.csv (ë°ì´í„°)")
        else:
            print("\nâŒ ì‹¤íŒ¨! ë¬¸ì œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nğŸ’¥ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
